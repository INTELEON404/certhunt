#!/usr/bin/env python3
import re
import argparse
import requests
import sys
import socket
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib3.exceptions import InsecureRequestWarning

# Disable SSL warnings for cleaner output
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

## # CONTEXT VARIABLES # ##
VERSION = "HUNTER v1"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "application/json, text/plain, */*"
}
TIMEOUT = 15

# Enhanced ANSI Color Palette
class Colors:
    BLUE   = '\033[38;5;33m'
    GREEN  = '\033[38;5;82m'
    YELLOW = '\033[38;5;226m'
    RED    = '\033[38;5;196m'
    CYAN   = '\033[38;5;51m'
    MAGENTA = '\033[38;5;201m'
    WHITE  = '\033[38;5;255m'
    GREY   = '\033[38;5;244m'
    BOLD   = '\033[1m'
    UNDERLINE = '\033[4m'
    ENDC   = '\033[0m'

def banner():
    """Prints a high-quality ASCII banner."""
    print(f"{Colors.CYAN}{Colors.BOLD}")
    print(r"""
░█▀▀░█▀▀░█▀▄░▀█▀░█░█░█░█░█▀█░▀█▀
░█░░░█▀▀░█▀▄░░█░░█▀█░█░█░█░█░░█░
░▀▀▀░▀▀▀░▀░▀░░▀░░▀░▀░▀▀▀░▀░▀░░▀░""")
    print(f"\n{Colors.BLUE}       Made By {Colors.BOLD}INTELEON404{Colors.ENDC} {Colors.BLUE} | {Colors.WHITE}VERSION {VERSION}{Colors.ENDC}")
    print(f"{Colors.GREY}        “AUTOMATED PASSIVE DOMAIN ENUMERATION”{Colors.ENDC}\n")

def clear_url(target):
    target = re.sub(r'^https?://', '', target.lower())
    target = target.replace('www.', '')
    return target.split('/')[0].strip()

def is_resolvable(domain):
    """Check if domain has a valid DNS record."""
    try:
        socket.gethostbyname(domain)
        return True
    except:
        return False

## # NETWORK UTILITIES # ##
def fetch_json(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT, verify=False)
        if r.status_code == 200:
            return r.json()
    except:
        pass
    return None

def fetch_text(url):
    try:
        r = requests.get(url, headers=HEADERS, timeout=TIMEOUT, verify=False)
        if r.status_code == 200:
            return r.text
    except:
        pass
    return None

## # SOURCE FUNCTIONS (Passive APIs) # ##

def from_crtsh(domain):
    results = set()
    data = fetch_json(f"https://crt.sh/?q=%.{domain}&output=json")
    if data:
        for entry in data:
            names = entry.get("name_value", "").split("\n")
            for name in names:
                clean_name = name.replace('*.', '').strip().lower()
                if clean_name.endswith(domain) and clean_name != domain:
                    results.add(clean_name)
    return results

def from_alienvault(domain):
    results = set()
    data = fetch_json(f"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/passive_dns")
    if data and "passive_dns" in data:
        for entry in data["passive_dns"]:
            host = entry.get("hostname", "").lower()
            if host and host.endswith(domain):
                results.add(host)
    return results

def from_hackertarget(domain):
    results = set()
    text = fetch_text(f"https://api.hackertarget.com/hostsearch/?q={domain}")
    if text:
        for line in text.splitlines():
            if "," in line:
                sub = line.split(",")[0].strip().lower()
                if sub.endswith(domain):
                    results.add(sub)
    return results

def from_anubis(domain):
    results = set()
    data = fetch_json(f"https://jldc.me/anubis/subdomains/{domain}")
    if data:
        for sub in data:
            if isinstance(sub, str) and sub.endswith(domain):
                results.add(sub.strip().lower())
    return results

def from_urlscan(domain):
    results = set()
    data = fetch_json(f"https://urlscan.io/api/v1/search/?q=domain:{domain}")
    if data and "results" in data:
        for item in data["results"]:
            sub = item.get("page", {}).get("domain", "").lower()
            if sub and sub.endswith(domain):
                results.add(sub)
    return results

def from_wayback(domain):
    results = set()
    url = f"https://web.archive.org/cdx/search/cdx?url=*.{domain}/*&output=json&collapse=urlkey&fl=original"
    data = fetch_json(url)
    if data:
        for entry in data[1:]:
            raw_url = entry[0]
            sub = re.sub(r'^https?://', '', raw_url).split('/')[0].split(':')[0].lower()
            sub = sub.replace('www.', '')
            if sub.endswith(domain):
                results.add(sub)
    return results

def from_rapiddns(domain):
    results = set()
    text = fetch_text(f"https://rapiddns.io/s/{domain}?full=1&down=1")
    if text:
        matches = re.findall(r'<td>([\w\.-]+\.' + re.escape(domain) + r')</td>', text)
        for sub in matches:
            results.add(sub.lower())
    return results

def from_threatminer(domain):
    results = set()
    data = fetch_json(f"https://api.threatminer.org/v2/domain.php?q={domain}&rt=5")
    if data and "results" in data:
        for sub in data["results"]:
            if isinstance(sub, str):
                results.add(sub.lower())
    return results

def from_certspotter(domain):
    results = set()
    data = fetch_json(f"https://api.certspotter.com/v1/issuances?domain={domain}&include_subdomains=true&expand=dns_names")
    if data:
        for entry in data:
            for name in entry.get("dns_names", []):
                clean_name = name.replace('*.', '').lower()
                if clean_name.endswith(domain):
                    results.add(clean_name)
    return results

def from_bevigil(domain):
    results = set()
    data = fetch_json(f"https://osint.bevigil.com/api/{domain}/subdomains/")
    if data and "subdomains" in data:
        for sub in data["subdomains"]:
            results.add(sub.lower())
    return results

def from_digitorum(domain):
    results = set()
    data = fetch_json(f"https://api.subdomain.center/?domain={domain}")
    if data:
        for sub in data:
            results.add(sub.lower())
    return results

def from_riddler(domain):
    results = set()
    data = fetch_json(f"https://riddler.io/api/search?q=pld:{domain}")
    if data:
        for entry in data:
            host = entry.get("host", "").lower()
            if host.endswith(domain):
                results.add(host)
    return results

## # MAIN ENGINE # ##

def parse_args():
    parser = argparse.ArgumentParser(description="Professional Passive Subdomain Enumerator")
    parser.add_argument("-d", "--domain", required=True, help="Target domain (e.g., example.com)")
    parser.add_argument("-v", "--verify", action="store_true", help="Verify if subdomains are alive (DNS resolution)")
    parser.add_argument("-t", "--threads", type=int, default=20, help="Number of threads for verification (Default: 20)")
    return parser.parse_args()

def main():
    banner()
    args = parse_args()
    target = clear_url(args.domain)

    print(f"{Colors.BOLD}{Colors.WHITE}[!] Target Domain : {Colors.CYAN}{target}{Colors.ENDC}")
    print(f"{Colors.BOLD}{Colors.WHITE}[!] Configuration : {Colors.YELLOW}Passive Scan Mode Activated{Colors.ENDC}")
    print(f"{Colors.GREY}{'-'*60}{Colors.ENDC}")

    sources = {
        "Crt.sh": from_crtsh,
        "Alienvault OTX": from_alienvault,
        "HackerTarget": from_hackertarget,
        "Anubis/JLDC": from_anubis,
        "UrlScan.io": from_urlscan,
        "Wayback Machine": from_wayback,
        "RapidDNS.io": from_rapiddns,
        "ThreatMiner": from_threatminer,
        "CertSpotter": from_certspotter,
        "BeVigil": from_bevigil,
        "SubdomainCenter": from_digitorum,
        "Riddler.io": from_riddler
    }

    all_found = set()

    # Discovery phase
    with ThreadPoolExecutor(max_workers=len(sources)) as executor:
        future_to_source = {executor.submit(func, target): name for name, func in sources.items()}

        for future in as_completed(future_to_source):
            source_name = future_to_source[future]
            try:
                data = future.result()
                count = len(data) if data else 0
                if count > 0:
                    print(f"{Colors.GREEN}[✓] {Colors.WHITE}{source_name:<18} : {Colors.BOLD}{count:>4}{Colors.ENDC} subs discovered")
                    all_found.update(data)
                else:
                    print(f"{Colors.RED}[✗] {Colors.GREY}{source_name:<18} : {Colors.BOLD}   0{Colors.ENDC} subs discovered")
            except Exception:
                print(f"{Colors.RED}[!] {source_name:<18} : API Connection Error{Colors.ENDC}")

    print(f"{Colors.GREY}{'-'*60}{Colors.ENDC}")
    print(f"{Colors.YELLOW}[*] Cleaning and filtering duplicates...{Colors.ENDC}")

    # Deduplication and filtering
    # Step 1: Normalize all findings (lowercase, strip whitespace and trailing dots)
    cleaned_results = set()
    for sub in all_found:
        clean_sub = sub.strip().lower().rstrip('.')
        if clean_sub.endswith(target) and clean_sub != target:
            cleaned_results.add(clean_sub)

    final_raw_results = sorted(list(cleaned_results))

    # Prominent Total Count
    total_raw = len(final_raw_results)
    print(f"{Colors.BOLD}{Colors.YELLOW}[★] TOTAL UNIQUE SUBDOMAINS FOUND: {Colors.WHITE}{total_raw}{Colors.ENDC}")

    # Domain Verification
    results_to_display = final_raw_results
    if args.verify:
        print(f"{Colors.MAGENTA}[*] Verifying DNS resolution for {total_raw} targets...{Colors.ENDC}")
        verified_list = []

        def check_sub(s):
            return s if is_resolvable(s) else None

        with ThreadPoolExecutor(max_workers=args.threads) as verify_executor:
            v_futures = [verify_executor.submit(check_sub, sub) for sub in final_raw_results]
            for f in as_completed(v_futures):
                res = f.result()
                if res:
                    verified_list.append(res)

        results_to_display = sorted(verified_list)
        print(f"{Colors.GREEN}[✓] TOTAL LIVE SUBDOMAINS: {Colors.BOLD}{len(results_to_display)}{Colors.ENDC}")

    # Final Result List Display
    if results_to_display:
        print(f"\n{Colors.BLUE}{Colors.BOLD}{'='*20} DISCOVERED LIST {'='*20}{Colors.ENDC}")
        for sub in results_to_display:
            parts = sub.rsplit(target, 1)
            # Extra safety check for prefix formatting
            prefix = parts[0] if parts[0] else ""
            print(f"{Colors.GREEN}·{Colors.ENDC} {Colors.WHITE}{prefix}{Colors.CYAN}{target}{Colors.ENDC}")
        print(f"{Colors.BLUE}{Colors.BOLD}{'='*57}{Colors.ENDC}")

    # Interactive Save Logic
    if results_to_display:
        print(f"\n{Colors.YELLOW}[?] Do you want to save the results? (y/n): {Colors.ENDC}", end="")
        choice = input().lower().strip()

        if choice == 'y':
            print(f"{Colors.YELLOW}[?] Enter filename (without extension): {Colors.ENDC}", end="")
            filename = input().strip()
            if not filename:
                filename = f"subdomains_{target}_{int(time.time())}"

            # Append .txt automatically
            full_filename = filename if filename.endswith(".txt") else f"{filename}.txt"

            try:
                with open(full_filename, "w") as f:
                    for sub in results_to_display:
                        f.write(sub + "\n")
                print(f"{Colors.GREEN}[✓] Results successfully saved to: {Colors.BOLD}{full_filename}{Colors.ENDC}")
            except Exception as e:
                print(f"{Colors.RED}[!] Error saving file: {e}{Colors.ENDC}")
        else:
            print(f"{Colors.GREY}[!] Results not saved.{Colors.ENDC}")

    print(f"\n{Colors.CYAN}{Colors.BOLD}Scan Finished. INTELEON404 at your service.{Colors.ENDC}")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print(f"\n{Colors.RED}[!] Interrupted by user. Exiting...{Colors.ENDC}")
        sys.exit(0)
