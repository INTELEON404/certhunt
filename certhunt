#!/usr/bin/env python3
import re
import argparse
import requests
import sys
import socket
import time
import shutil
import itertools
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib3.exceptions import InsecureRequestWarning

# DISABLE SSL WARNINGS
requests.packages.urllib3.disable_warnings(category=InsecureRequestWarning)

VERSION = "HUNTER v1.3"
HEADERS = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36"
}
TIMEOUT = 35

class Colors:
    MINT     = '\033[38;5;121m'
    SKY      = '\033[38;5;117m'
    GOLD     = '\033[38;5;222m'
    CORAL    = '\033[38;5;210m'
    LAVENDER = '\033[38;5;183m'
    SILVER   = '\033[38;5;249m'
    SLATE    = '\033[38;5;241m'
    BOLD     = '\033[1m'
    ENDC     = '\033[0m'

stop_animation = False
session = requests.Session()
session.headers.update(HEADERS)

def status_log(msg, color=Colors.SILVER):
    if sys.stdout.isatty():
        print(f"{color}{msg}{Colors.ENDC}")

def loading_animation():
    """আপনার দেওয়া ব্রেইল ক্যারেক্টার দিয়ে লোডিং স্পিনার"""
    # '⠏', '⠛', '⠹', '⠸', '⠼', '⠴', '⠦', '⠧', '⠇', '⠍'
    spinner = itertools.cycle(['⠏', '⠛', '⠹', '⠸', '⠼', '⠴', '⠦', '⠧', '⠇', '⠍'])
    while not stop_animation:
        char = next(spinner)
        sys.stdout.write(f"\r {Colors.MINT}{char}{Colors.ENDC} {Colors.GOLD}EXTRACTING DEEP DATA...{Colors.ENDC}")
        sys.stdout.flush()
        time.sleep(0.1)
    sys.stdout.write("\r" + " " * 50 + "\r")

def get_banner():
    if sys.stdout.isatty():
        columns = shutil.get_terminal_size().columns
        width = max(columns, 70)
        art = [
            "░█▀▀░█▀▀░█▀▄░▀█▀░█░█░█░█░█▀█░▀█▀",
            "░█░░░█▀▀░█▀▄░░█░░█▀█░█░█░█░█░░█░",
            "░▀▀▀░▀▀▀░▀░▀░░▀░░▀░▀░▀▀▀░▀░▀░░▀░"
        ]
        print(f"{Colors.SKY}{Colors.BOLD}")
        for line in art:
            print(line.center(width))
        info = f"DEVELOPED BY INTELEON404 | VERSION {VERSION}"
        tagline = "“ADVANCED SUBDOMAIN RECONNAISSANCE”"
        print(f"\n{Colors.LAVENDER}{info.center(width)}{Colors.ENDC}")
        print(f"{Colors.SLATE}{tagline.center(width)}{Colors.ENDC}\n")

def clean_target(domain):
    domain = re.sub(r'^https?://', '', domain.lower())
    domain = domain.replace('www.', '')
    return domain.split('/')[0].strip()

def dns_resolver(domain):
    try:
        socket.gethostbyname(domain)
        return True
    except:
        return False

def request_api(url, is_json=True):
    try:
        resp = session.get(url, timeout=TIMEOUT, verify=False)
        if resp.status_code == 200:
            return resp.json() if is_json else resp.text
    except:
        pass
    return None

def extract_all(text, domain):
    pattern = r'(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?\.)+' + re.escape(domain)
    matches = re.findall(pattern, str(text).lower())
    return {m.strip() for m in matches}

# --- SOURCE ENGINES ---

def source_abuseipdb(domain):
    res = request_api(f"https://www.abuseipdb.com/whois/{domain}", is_json=False)
    return extract_all(res, domain) if res else set()

def source_alienvault(domain):
    data = request_api(f"https://otx.alienvault.com/api/v1/indicators/domain/{domain}/passive_dns")
    return {entry.get("hostname", "").lower() for entry in data.get("passive_dns", []) if entry.get("hostname", "").endswith(domain)} if data else set()

def source_anubis(domain):
    data = request_api(f"https://jldc.me/anubis/subdomains/{domain}")
    return {s.strip().lower() for s in data if isinstance(s, str) and s.endswith(domain)} if data else set()

def source_bevigil(domain):
    data = request_api(f"https://osint.bevigil.com/api/{domain}/subdomains/")
    return {s.lower() for s in data.get("subdomains", [])} if data else set()

def source_bufferover(domain):
    data = request_api(f"https://dns.bufferover.run/dns?q=.{domain}")
    return {entry.split(",")[1].lower() for entry in data.get("FDNS_A", []) if "," in entry} if data else set()

def source_certspotter(domain):
    data = request_api(f"https://api.certspotter.com/v1/issuances?domain={domain}&include_subdomains=true&expand=dns_names")
    subs = set()
    if data:
        for entry in data:
            for name in entry.get("dns_names", []):
                clean = name.replace('*.', '').lower()
                if clean.endswith(domain): subs.add(clean)
    return subs

def source_commoncrawl(domain):
    url = f"http://index.commoncrawl.org/CC-MAIN-2023-50-index?url=*.{domain}/*&output=json"
    res = request_api(url, is_json=False)
    return extract_all(res, domain) if res else set()

def source_crtsh(domain):
    data = request_api(f"https://crt.sh/?q=%.{domain}&output=json")
    subs = set()
    if data:
        for item in data:
            for name in item.get("name_value", "").split("\n"):
                clean = name.replace('*.', '').strip().lower()
                if clean.endswith(domain): subs.add(clean)
    return subs

def source_fullhunt(domain):
    data = request_api(f"https://fullhunt.io/api/v1/domain/{domain}/subdomains")
    return {s.lower() for s in data.get("hosts", [])} if data else set()

def source_hackertarget(domain):
    res = request_api(f"https://api.hackertarget.com/hostsearch/?q={domain}", is_json=False)
    return extract_all(res, domain) if res else set()

def source_netcraft(domain):
    res = request_api(f"https://searchdns.netcraft.com/?restriction=site+ends+with&host={domain}", is_json=False)
    return extract_all(res, domain) if res else set()

def source_omnisint(domain):
    data = request_api(f"https://sonar.omnisint.io/all/{domain}")
    return {s.lower() for s in data if isinstance(s, str)} if data else set()

def source_rapiddns(domain):
    res = request_api(f"https://rapiddns.io/s/{domain}?full=1&down=1", is_json=False)
    return extract_all(res, domain) if res else set()

def source_sitedossier(domain):
    res = request_api(f"http://www.sitedossier.com/parentdomain/{domain}", is_json=False)
    return extract_all(res, domain) if res else set()

def source_subdomaincenter(domain):
    data = request_api(f"https://api.subdomain.center/?domain={domain}")
    return {s.lower() for s in data if isinstance(s, str)} if data else set()

def source_synapsint(domain):
    data = request_api(f"https://synapsint.com/report.php?domain={domain}", is_json=False)
    return extract_all(data, domain) if data else set()

def source_urlscan(domain):
    data = request_api(f"https://urlscan.io/api/v1/search/?q=domain:{domain}")
    subs = set()
    if data and "results" in data:
        for item in data["results"]:
            sub = item.get("page", {}).get("domain", "").lower()
            if sub.endswith(domain): subs.add(sub)
    return subs

def source_virustotal(domain):
    data = request_api(f"https://www.virustotal.com/ui/domains/{domain}/subdomains?limit=40")
    return {entry.get("id", "").lower() for entry in data.get("data", [])} if data else set()

def source_wayback(domain):
    url = f"https://web.archive.org/cdx/search/cdx?url=*.{domain}/*&output=json&collapse=urlkey&fl=original"
    res = request_api(url, is_json=False)
    return extract_all(res, domain) if res else set()

# --- EXECUTION ---

def main():
    global stop_animation
    parser = argparse.ArgumentParser(description="HUNTER ULTRA RECON")
    parser.add_argument("-d", "--domain", required=True, help="TARGET DOMAIN")
    parser.add_argument("-v", "--verify", action="store_true", help="VERIFY LIVE STATUS")
    parser.add_argument("-t", "--threads", type=int, default=60, help="THREADS")
    args = parser.parse_args()

    target = clean_target(args.domain)
    get_banner()

    status_log(f"[*] TARGETING : {target.upper()}", Colors.SKY)
    status_log(f"[*] SOURCES   : 19 PASSIVE ENGINES ACTIVATED", Colors.GOLD)
    status_log(f"{Colors.SLATE}{'-' * 60}{Colors.ENDC}")

    engines = [
        source_abuseipdb, source_alienvault, source_anubis, source_bevigil,
        source_bufferover, source_certspotter, source_commoncrawl, source_crtsh,
        source_fullhunt, source_hackertarget, source_netcraft, source_omnisint,
        source_rapiddns, source_sitedossier, source_subdomaincenter,
        source_synapsint, source_urlscan, source_virustotal, source_wayback
    ]

    discovered = set()
    results_map = {}
    
    if sys.stdout.isatty():
        anim_thread = threading.Thread(target=loading_animation)
        anim_thread.start()

    with ThreadPoolExecutor(max_workers=len(engines)) as executor:
        task_map = {executor.submit(eng, target): eng.__name__.replace('source_', '').upper() for eng in engines}
        for task in as_completed(task_map):
            name = task_map[task]
            try:
                found = task.result()
                results_map[name] = found
                if found: discovered.update(found)
            except:
                results_map[name] = set()

    stop_animation = True
    if sys.stdout.isatty():
        anim_thread.join()

    for name in sorted(results_map.keys()):
        count = len(results_map[name])
        if count > 0:
            status_log(f" {Colors.MINT}[✓]{Colors.ENDC} {name:<18} : {Colors.BOLD}{count}{Colors.ENDC} FOUND", Colors.SILVER)
        else:
            status_log(f" {Colors.CORAL}[✗]{Colors.ENDC} {name:<18} : 0 FOUND", Colors.SLATE)

    final_list = {s.strip().lower().rstrip('.') for s in discovered if s.endswith(target) and s != target}
    final_list = sorted(list(final_list))

    status_log(f"{Colors.SLATE}{'-' * 60}{Colors.ENDC}")
    status_log(f" {Colors.LAVENDER}[★] TOTAL UNIQUE DISCOVERED: {len(final_list)}{Colors.ENDC}", Colors.BOLD)

    if args.verify and final_list:
        status_log(f" [*] VERIFYING LIVE STATUS...", Colors.GOLD)
        live = []
        with ThreadPoolExecutor(max_workers=args.threads) as v_exec:
            v_tasks = {v_exec.submit(dns_resolver, s): s for s in final_list}
            for vt in as_completed(v_tasks):
                if vt.result(): live.append(v_tasks[vt])
        final_list = sorted(live)
        status_log(f" {Colors.MINT}[✓] TOTAL LIVE HOSTS FOUND: {len(final_list)}{Colors.ENDC}", Colors.BOLD)

    if not sys.stdout.isatty():
        for s in final_list: sys.stdout.write(s + "\n")
    else:
        if final_list:
            print(f"\n{Colors.SKY}{Colors.BOLD}{'='*25} RESULTS {'='*25}{Colors.ENDC}")
            for s in final_list:
                print(f" {Colors.MINT}→{Colors.ENDC} {Colors.SILVER}{s}{Colors.ENDC}")
            print(f"{Colors.SKY}{Colors.BOLD}{'='*59}{Colors.ENDC}")
            
            save_opt = input(f"\n{Colors.GOLD}[?] EXPORT RESULTS? (Y/N): {Colors.ENDC}").lower()
            if save_opt == 'y':
                fname = input(f"{Colors.GOLD}[?] FILENAME: {Colors.ENDC}") or f"hunter_{target}.txt"
                with open(fname, "w") as f: f.write("\n".join(final_list))
                print(f" {Colors.MINT}[✓] DATA EXPORTED TO: {fname}{Colors.ENDC}")

    status_log(f"\n {Colors.SKY}[!] SCAN COMPLETED. HAPPY HUNTING!{Colors.ENDC}")

if __name__ == "__main__":
    try: main()
    except KeyboardInterrupt:
        stop_animation = True
        status_log("\n [!] SESSION TERMINATED.", Colors.CORAL)
        sys.exit(0)
